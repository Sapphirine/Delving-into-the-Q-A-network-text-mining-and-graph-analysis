learn rate relat shape error gradient asit dictat rate descent ?in plain sgd global learn rate use indiffer error gradient howev intuit get inspir variou modif sgd updat rule use inform inform decis valu ?adagrad wide known scale global learn rate dimens base l2 norm histori error gradient gt dimens adadelta anoth train algorithm use error gradient histori like adagrad weight updat histori advantag set learn rate sort valu choos choos ?set learn rate plain sgd neural net usual aprocess start sane valu 0 01 cross validationto find optim valu typic valu rang order ofmagnitud 0 0001 1 seem like would want small valu avoid overshoot buthow choos one get stuck local minimaor take long descend ? make sens constant learn rate use metric alter valu get nearer minimum gradient ?usual valu best near highest stabl learningr learn rate decay anneal either linear orexponenti use cours train reason behind earli clear learn signal aggress updat encourag explor later smaller learn rate allow delic exploit local error surfac