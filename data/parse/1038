use deep network ?let first tri solv simpl classif task say moder web forum sometim flood spam messag messag easili identifi often contain specif word like buy porn etc url outer resourc want creat filter alert suspeci messag turn pretti easi get list featur e g list suspici word presenc url train simpl logist regress k perceptron e model like g w0 w1 x1 w2 x2 wnxn x1 xn featur either presenc specif word url w0 wn learn coeffici g logist function make result 0 1 simpl classifi simpl task may give good result creat linear decis boundari assum use 2 featur boundari may look someth like 2 axe repres featur e g number occurr specif word messag normal around zero red point stay spam blue point normal messag black line show separ line soon notic good messag contain lot occurr word buy url extend discuss porn detect actual reffer porn movi linear decis boundari simpli cannot handl situat instead need someth like new non linear decis boundari much flexibl e fit data much closer mani way achiev non linear use polynomi featur e g x1 2 combin e g x1 x2 project higher dimens like kernel method neural network common solv combin perceptron word build multilay perceptron non linear come logist function layer layer sophist pattern may cover mlp singl layer perceptron handl simpl spam detect network 2 3 layer catch tricki combin featur network 5 9 layer use larg research lab compani like googl may model whole languag detect cat imag essenti reason deep architectur model sophist pattern deep network hard train ?with one featur linear decis boundari fact enough 2 train exampl one posit one neg sever featur non linear decis boundari need sever order exampl cover possibl case e g need find exampl word1 word2 word3 also possibl combin real life need deal hundr thousand featur e g word languag pixel imag least sever layer enough non linear size data set need fulli train network easili exce 10 30 exampl make total imposs get enough data word mani featur mani layer decis function becom flexibl abl learn precis howev way learn approxim exampl work probabilist set instead learn frequenc combin featur could assum independ learn individu frequenc reduc full unconstrain bay classifi naiv bay thu requir much much less data learn neural network sever attempt meaning reduc complex flexibl decis function exampl convolut network extens use imag classif assum local connect nearbi pixel thu tri learn combin pixel insid small window say 16x16 pixel 256 input neuron oppos full imag say 100x100 pixel 10000 input neuron approach includ featur engin e search specif human discov descriptor input data manual discov featur promis actual natur languag process exampl sometim help use special dictionari like contain spam specif word catch negat e g good comput vision thing like surf descriptor haar like featur almost irreplac problem manual featur engin take liter year come good descriptor moreov featur often specif unsupervis pretrainingbut turn obtain good featur automat right data use algorithm autoencod restrict boltzmann machin describ detail answer short allow find repeat pattern input data transform higher level featur exampl given row pixel valu input algorithm may identifi pass higher whole edg edg construct figur get realli high level descriptor like variat face unsupervis pretrain network usual convert mlp use normal supervis train note pretrain done layer wise significantli reduc solut space learn algorithm thu number train exampl need need learn paramet insid layer without take account layer beyond unsupervis pretrain time recent algorithm found improv learn togeth pretrain without one notabl exampl algorithm dropout simpl techniqu randomli drop neuron train creatig distort prevent network follow data close still hot research topic leav reader